{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edaacb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62999c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config \n",
    "# Choose what to evaluate\n",
    "TARGET = \"wpa\"        # or \"epa\"\n",
    "SEASON = 2024         # or None for all seasons\n",
    "POLICY = \"eps\"        # \"greedy\" or \"eps\"\n",
    "EPS = 0.05            # epsilon for eps-greedy\n",
    "CLIP = None           # e.g., 50 for weight clipping sensitivity, else None\n",
    "BOOTSTRAP = 1000      # resamples for 95% CI\n",
    "\n",
    "DATA_PATH = \"data/decisions_2016_2024.csv\"\n",
    "\n",
    "# For sanity in prints\n",
    "np.set_printoptions(suppress=True, linewidth=120)\n",
    "pd.set_option(\"display.width\", 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5413a08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded artifacts.\n",
      "Actions order: ['fg', 'go', 'punt'] \n",
      "#Features: 28\n"
     ]
    }
   ],
   "source": [
    "#Load artifacts (preprocessor, behavior policy, arm models, metadata)\n",
    "pre = load(\"artifacts/preprocessor.joblib\")\n",
    "behavior = load(\"artifacts/behavior_policy.joblib\")          # must expose predict_proba\n",
    "arm_models = load(f\"artifacts/arm_models_{TARGET}.joblib\")   # dict: {'go': model, 'fg': model, 'punt': model}\n",
    "\n",
    "with open(\"artifacts/metadata.json\",\"r\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "actions = meta[\"actions\"]  # expected: [\"go\",\"punt\",\"fg\"] (order matters)\n",
    "if set(actions) != {\"go\",\"punt\",\"fg\"}:\n",
    "    raise ValueError(f\"Unexpected actions in metadata: {actions}\")\n",
    "\n",
    "# exactly the columns used at train time\n",
    "feature_cols = meta.get(\"feature_cols\") or (meta[\"numeric_features\"] + meta[\"categorical_features\"])\n",
    "print(\"Loaded artifacts.\\nActions order:\", actions, \"\\n#Features:\", len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45810a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval rows: 3634 | Reward column: wpa\n",
      "['season', 'week', 'game_id', 'game_date', 'play_id', 'posteam', 'defteam', 'home_team', 'away_team', 'posteam_type', 'qtr', 'game_seconds_remaining', 'half_seconds_remaining', 'quarter_seconds_remaining', 'down', 'ydstogo', 'yardline_100', 'score_differential', 'home_timeouts_remaining', 'away_timeouts_remaining', 'posteam_timeouts_remaining', 'defteam_timeouts_remaining', 'roof', 'surface', 'temp', 'wind', 'play_type', 'punt_attempt', 'field_goal_attempt', 'rush_attempt', 'pass_attempt', 'epa', 'wpa', 'success', 'yards_gained', 'first_down', 'touchdown', 'field_goal_result', 'kick_distance', 'punt_inside_twenty', 'punt_out_of_bounds', 'punt_downed', 'punt_fair_catch', 'return_yards', 'penalty', 'aborted_play', 'play_deleted', 'goal_to_go', 'timeout', 'timeout_team', 'off_epa_4w', 'def_epa_4w', 'plays_in_drive_so_far', 'play_elapsed_s', 'game_time_elapsed', 'def_time_on_field_cum', 'def_time_on_field_share', 'is_q4_or_later', 'action', 'fg_pct_short', 'fg_pct_mid', 'fg_pct_long', 'punt_net_4w']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>play_id</th>\n",
       "      <th>posteam</th>\n",
       "      <th>defteam</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>posteam_type</th>\n",
       "      <th>...</th>\n",
       "      <th>play_elapsed_s</th>\n",
       "      <th>game_time_elapsed</th>\n",
       "      <th>def_time_on_field_cum</th>\n",
       "      <th>def_time_on_field_share</th>\n",
       "      <th>is_q4_or_later</th>\n",
       "      <th>action</th>\n",
       "      <th>fg_pct_short</th>\n",
       "      <th>fg_pct_mid</th>\n",
       "      <th>fg_pct_long</th>\n",
       "      <th>punt_net_4w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28215</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>2024_01_ARI_BUF</td>\n",
       "      <td>2024-09-08</td>\n",
       "      <td>823.0</td>\n",
       "      <td>ARI</td>\n",
       "      <td>BUF</td>\n",
       "      <td>BUF</td>\n",
       "      <td>ARI</td>\n",
       "      <td>away</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>0.841111</td>\n",
       "      <td>0</td>\n",
       "      <td>fg</td>\n",
       "      <td>0.924842</td>\n",
       "      <td>0.720459</td>\n",
       "      <td>0.719610</td>\n",
       "      <td>32.886762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28216</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>2024_01_ARI_BUF</td>\n",
       "      <td>2024-09-08</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>BUF</td>\n",
       "      <td>ARI</td>\n",
       "      <td>BUF</td>\n",
       "      <td>ARI</td>\n",
       "      <td>home</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.363937</td>\n",
       "      <td>0</td>\n",
       "      <td>fg</td>\n",
       "      <td>0.950380</td>\n",
       "      <td>0.738880</td>\n",
       "      <td>0.652809</td>\n",
       "      <td>30.212951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  week          game_id   game_date  play_id posteam defteam home_team away_team posteam_type  ...  \\\n",
       "28215    2024     1  2024_01_ARI_BUF  2024-09-08    823.0     ARI     BUF       BUF       ARI         away  ...   \n",
       "28216    2024     1  2024_01_ARI_BUF  2024-09-08   1120.0     BUF     ARI       BUF       ARI         home  ...   \n",
       "\n",
       "       play_elapsed_s  game_time_elapsed  def_time_on_field_cum  def_time_on_field_share  is_q4_or_later  action  \\\n",
       "28215             0.0              900.0                  757.0                 0.841111               0      fg   \n",
       "28216            40.0             1209.0                  440.0                 0.363937               0      fg   \n",
       "\n",
       "       fg_pct_short  fg_pct_mid  fg_pct_long  punt_net_4w  \n",
       "28215      0.924842    0.720459     0.719610    32.886762  \n",
       "28216      0.950380    0.738880     0.652809    30.212951  \n",
       "\n",
       "[2 rows x 63 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load evaluation data and select columns\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "if SEASON is not None and \"season\" in df.columns:\n",
    "    df = df.loc[df[\"season\"].astype(int) == int(SEASON)].copy()\n",
    "\n",
    "# Normalize action labels to the metadata actions\n",
    "a_logged_raw = (\n",
    "    df[\"action\"]\n",
    "      .astype(str).str.lower()\n",
    "      .replace({\"field_goal\":\"fg\",\"fieldgoal\":\"fg\",\"field goal\":\"fg\",\n",
    "                \"go_for_it\":\"go\",\"go-for-it\":\"go\",\"go for it\":\"go\"})\n",
    ")\n",
    "if not set(a_logged_raw.unique()).issubset(set(actions)):\n",
    "    print(\"WARNING: Found actions not in metadata:\", sorted(set(a_logged_raw.unique()) - set(actions)))\n",
    "\n",
    "r = df[TARGET].astype(float).to_numpy()\n",
    "X_raw = df[feature_cols].copy()\n",
    "\n",
    "print(\"Eval rows:\", len(df), \"| Reward column:\", TARGET)\n",
    "print(df.columns.tolist())\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92d58e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3634, 160)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build design matrix (using the same fitted preprocessor)\n",
    "X_design = pre.transform(X_raw)  # sparse or dense depending on your preprocessor\n",
    "X_design.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d6a134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93372766, 0.06308965, 0.00318269],\n",
       "       [0.97730246, 0.02092129, 0.00177625],\n",
       "       [0.00014639, 0.00134649, 0.99850712]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Behavior policy probabilities π_b(a|x)\n",
    "\n",
    "# Works whether `behavior` is a Pipeline (with pre inside) or a bare estimator (expects preprocessed X)\n",
    "try:\n",
    "    P_beh_raw = behavior.predict_proba(X_raw)        # if Pipeline\n",
    "except Exception:\n",
    "    P_beh_raw = behavior.predict_proba(X_design)     # if bare estimator\n",
    "\n",
    "# Get classes from the behavior model\n",
    "if hasattr(behavior, \"classes_\"):\n",
    "    beh_classes = list(behavior.classes_)\n",
    "else:\n",
    "    beh_lr = getattr(getattr(behavior, \"named_steps\", {}), \"get\", lambda _: None)(\"logisticregression\")\n",
    "    beh_classes = list(getattr(beh_lr, \"classes_\", []))\n",
    "    if not beh_classes:\n",
    "        raise RuntimeError(\"Could not infer classes_ from behavior model.\")\n",
    "\n",
    "# Reindex to metadata actions order\n",
    "colmap = {c:i for i,c in enumerate(beh_classes)}\n",
    "P_beh = np.column_stack([P_beh_raw[:, colmap[a]] for a in actions])  # shape (N, K)\n",
    "P_beh[:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9334ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01894225,  0.01925375,  0.01047604],\n",
       "       [ 0.01155332,  0.00034312,  0.00285456],\n",
       "       [ 0.02319527,  0.01586833,  0.01157821]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Per-action value predictions μ̂(x,a) for all actions\n",
    "def mu_matrix(arm_models, X_design, actions):\n",
    "    N = X_design.shape[0]; K = len(actions)\n",
    "    MU = np.zeros((N, K), dtype=float)\n",
    "    for j, a in enumerate(actions):\n",
    "        m = arm_models[a]\n",
    "        if isinstance(m, tuple) and m[0] == \"const\":      # your code uses (\"const\", mu) when data is sparse\n",
    "            MU[:, j] = float(m[1])\n",
    "        else:\n",
    "            MU[:, j] = m.predict(X_design)\n",
    "    return MU\n",
    "\n",
    "MU = mu_matrix(arm_models, X_design, actions)  # (N,3)\n",
    "MU[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e02daac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01666667, 0.96666667, 0.01666667],\n",
       "       [0.96666667, 0.01666667, 0.01666667],\n",
       "       [0.96666667, 0.01666667, 0.01666667]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Candidate policy π_new(a|x): greedy or ε-greedy\n",
    "def policy_greedy(MU):\n",
    "    N, K = MU.shape\n",
    "    idx = MU.argmax(axis=1)\n",
    "    P = np.zeros_like(MU)\n",
    "    P[np.arange(N), idx] = 1.0\n",
    "    return P\n",
    "\n",
    "def policy_eps_greedy(MU, eps=0.05):\n",
    "    N, K = MU.shape\n",
    "    P = np.full((N, K), eps/float(K))\n",
    "    best = MU.argmax(axis=1)\n",
    "    P[np.arange(N), best] += 1.0 - eps\n",
    "    return P\n",
    "\n",
    "P_eval = policy_greedy(MU) if POLICY == \"greedy\" else policy_eps_greedy(MU, eps=EPS)\n",
    "P_eval[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b387f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DM=0.019459  IPS=-0.003502  SNIPS=-0.002789  DR=0.006058  ESS=24.7/3634\n"
     ]
    }
   ],
   "source": [
    "#Tie logged actions to indices and compute estimators (DM, IPS, SNIPS, DR)\n",
    "\n",
    "# map logged action strings to column indices\n",
    "act_map = {a:i for i,a in enumerate(actions)}\n",
    "a_idx = a_logged_raw.map(act_map).to_numpy()\n",
    "\n",
    "def estimators(P_eval, P_beh, MU, r, a_idx, clip=None):\n",
    "    eps = 1e-6\n",
    "    N = len(r)\n",
    "    pi_e_logged = P_eval[np.arange(N), a_idx]\n",
    "    pi_b_logged = P_beh[np.arange(N), a_idx]\n",
    "    w = pi_e_logged / np.clip(pi_b_logged, eps, None)\n",
    "\n",
    "    if clip is not None:\n",
    "        w_eff = np.clip(w, 0, float(clip))\n",
    "    else:\n",
    "        w_eff = w\n",
    "\n",
    "    mu_logged = MU[np.arange(N), a_idx]\n",
    "    mu_target = np.sum(P_eval * MU, axis=1)\n",
    "\n",
    "    DM = mu_target.mean()\n",
    "    IPS = np.mean(w_eff * r)\n",
    "    SNIPS = (w_eff * r).sum() / (w_eff.sum() + eps)\n",
    "    DR = np.mean(w_eff * (r - mu_logged) + mu_target)\n",
    "\n",
    "    # Effective sample size on rows where eval policy puts positive mass\n",
    "    mask_pos = pi_e_logged > 0\n",
    "    w_pos = w[mask_pos]\n",
    "    ESS = (w_pos.sum()**2) / (np.sum(w_pos**2) + eps) if w_pos.size else 0.0\n",
    "\n",
    "    return DM, IPS, SNIPS, DR, ESS, w\n",
    "\n",
    "DM, IPS, SNIPS, DR, ESS, w = estimators(P_eval, P_beh, MU, r, a_idx, clip=CLIP)\n",
    "print(f\"DM={DM:.6f}  IPS={IPS:.6f}  SNIPS={SNIPS:.6f}  DR={DR:.6f}  ESS={ESS:.1f}/{len(r)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d959c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DM 95% CI    [0.019037, 0.019943]\n",
      "IPS 95% CI   [-0.033645, 0.018612]\n",
      "SNIPS 95% CI [-0.021899, 0.017847]\n",
      "DR 95% CI    [-0.026982, 0.029934]\n"
     ]
    }
   ],
   "source": [
    "#Bootstrap 95% CIs (recommended for the report)\n",
    "\n",
    "def bootstrap_all(P_eval, P_beh, MU, r, a_idx, B=1000, alpha=0.05, seed=123, clip=None):\n",
    "    rs = np.random.RandomState(seed)\n",
    "    n = len(r)\n",
    "    dm_l, ips_l, snips_l, dr_l = [], [], [], []\n",
    "    for _ in range(B):\n",
    "        idx = rs.randint(0, n, n)\n",
    "        DM_b, IPS_b, SNIPS_b, DR_b, _, _ = estimators(P_eval[idx], P_beh[idx], MU[idx], r[idx], a_idx[idx], clip=clip)\n",
    "        dm_l.append(DM_b); ips_l.append(IPS_b); snips_l.append(SNIPS_b); dr_l.append(DR_b)\n",
    "    def ci(arr):\n",
    "        return float(np.quantile(arr, alpha/2)), float(np.quantile(arr, 1 - alpha/2))\n",
    "    return ci(dm_l), ci(ips_l), ci(snips_l), ci(dr_l)\n",
    "\n",
    "ci_dm, ci_ips, ci_snips, ci_dr = bootstrap_all(P_eval, P_beh, MU, r, a_idx, B=BOOTSTRAP, clip=CLIP)\n",
    "print(f\"DM 95% CI    [{ci_dm[0]:.6f}, {ci_dm[1]:.6f}]\")\n",
    "print(f\"IPS 95% CI   [{ci_ips[0]:.6f}, {ci_ips[1]:.6f}]\")\n",
    "print(f\"SNIPS 95% CI [{ci_snips[0]:.6f}, {ci_snips[1]:.6f}]\")\n",
    "print(f\"DR 95% CI    [{ci_dr[0]:.6f}, {ci_dr[1]:.6f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "253a48b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (behavior) — DR: 0.0016606480107016685\n",
      "Your policy          — DR: 0.0060584471560989565\n",
      "Lift (WPA): 0.004397799145397288\n"
     ]
    }
   ],
   "source": [
    "#Compare against the baseline “behavior” policy\n",
    "#  Evaluate baseline by setting P_eval = P_beh\n",
    "P_eval_base = P_beh.copy()\n",
    "DM_b, IPS_b, SNIPS_b, DR_b, ESS_b, _ = estimators(P_eval_base, P_beh, MU, r, a_idx)\n",
    "print(\"Baseline (behavior) — DR:\", DR_b)\n",
    "print(\"Your policy          — DR:\", DR)\n",
    "print(\"Lift (WPA):\", DR - DR_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a899b8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 20): DR=0.0109, ESS=97.0/612\n",
      "[20, 40): DR=0.0148, ESS=206.8/787\n",
      "[40, 60): DR=0.0182, ESS=97.2/855\n",
      "[60, 80): DR=0.0365, ESS=12.0/1093\n",
      "[80, 100): DR=-0.1802, ESS=2.5/287\n"
     ]
    }
   ],
   "source": [
    "#Context slices (to show where it helps)\n",
    "bins = pd.cut(df['yardline_100'], [0,20,40,60,80,100], right=False)\n",
    "for b in bins.cat.categories:\n",
    "    mask = (bins == b).to_numpy()\n",
    "    dm, ips, snips, dr, ess, _ = estimators(P_eval[mask], P_beh[mask], MU[mask], r[mask], a_idx[mask])\n",
    "    print(f\"{b}: DR={dr:.4f}, ESS={ess:.1f}/{mask.sum()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
